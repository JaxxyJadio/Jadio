# === Batch Processing Super Config ===

# Directories
input_dir: ../dataset_rawdump
output_dir: ../dataset_factory
log_dir: ../dataset_logs
manifest_log: ../dataset_logs/manifest.log

# File selection
supported_types: [json, csv, txt, parquet]
include_patterns: ['*.json', '*.csv', '*.txt', '*.parquet']  # Explicitly match all supported file types
exclude_patterns: []
min_file_size: 0      # in bytes
max_file_size: 0      # 0 = unlimited
modified_after: null  # e.g. '2025-01-01'
modified_before: null

# Processing
parallelism: 4           # Safer for 16GB RAM (i7-14700F)
use_gpu: true           # Enable GPU if supported
max_files: 0            # 0 = unlimited
batch_size: 1           # 1 file per worker (safe for memory)
max_inflight_tasks: 6   # Limit total concurrent file processing (4 workers + 2 buffer)
memory_limit_mb: 2048   # 2GB per worker (safe for 16GB RAM)

# Preprocessing/Postprocessing
preprocess_steps: []
postprocess_steps: []

# Output
output_format: jsonl
overwrite_existing: false
compress_output: false  # Set true if you want to save disk space

# Logging
log_level: INFO
progress_bar: true
log_to_file: true
log_to_console: true
log_format: '[{level}] {time} {message}'

# Error Handling
retry_on_fail: true
max_retries: 2
skip_on_error: true
error_log: ../dataset_logs/error.log

# Manifest/Reporting
manifest_log: ../dataset_logs/manifest.log
summary_report: true
summary_format: text

# Hooks
pre_run_hook: null
post_run_hook: null

# Dry Run/Test Mode
dry_run: false

# Notifications
notify_on_complete: false
notification_email: null

# Add more advanced options as needed

# In config.yaml, set include_patterns to ['*.*'] for all files with an extension, or specify extensions as needed
# Example:
# include_patterns: ['*.json', '*.csv', '*.txt', '*.parquet']
# This avoids matching files literally named '*', and matches only real data files.